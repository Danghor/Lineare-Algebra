\chapter{Vektor-Räume}
In diesem Kapitel werden wir zunächst den für den Rest dieser Vorlesung grundlegenden
Begriff des \href{https://de.wikipedia.org/wiki/Vektorraum}{Vektor-Raums}
einführen.  Die Theorie der Vektor-Räume bildet die Grundlage für unsere spätere
Behandlung \href{https://de.wikipedia.org/wiki/Lineares_Gleichungssystem}{linearer Gleichungs-Systeme}. 
Außerdem benötigen wir Vektor-Räume bei der Lösung von
\href{https://en.wikipedia.org/wiki/Recurrence_relation}{Rekurrenz-Gleichungen}, die wir im letzten  
Kapitel dieses Skriptes diskutieren.  Daneben gibt es zahlreiche weitere Anwendungen von Vektor-Räumen in der
Informatik.  Diese alle aufzulisten würde Ihnen jetzt wenig helfen, wir beginnen stattdessen mit
der Definition. 

\renewcommand{\labelenumi}{\arabic{enumi}.}
\renewcommand{\labelenumii}{(\alph{enumii})}

\section{Definition und Beispiele}
\begin{Definition}[Vektor-Raum]
  Es sei $\mathbb{K} = \langle K, 0, 1, +, \cdot \rangle$ ein Körper.  Dann bezeichnen wir ein Paar
  $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$ als einen \blue{$\mathbb{K}$-Vektor-Raum} falls gilt:
\begin{enumerate}
\item $\langle V, \vec{0}, + \rangle$ ist eine kommutative Gruppe.
\item $\cdot: K \times V \rightarrow V$ ist eine Abbildung, die jeder Zahl $\lambda \in K$ und jedem 
      $\vec{x} \in V$ ein Element $\lambda \cdot \vec{x} \in V$ zuordnet. 
      Diese Funktion  wird als \blue{Skalar-Multiplikation} bezeichnet und
      üblicherweise in Infix-Notation geschrieben. 

      Die Skalar-Multiplikation muss außerdem den folgenden Gesetzen genügen:
      \begin{enumerate}
      \item $(\alpha \cdot \beta)  \cdot \vec{x} =  \alpha \cdot (\beta \cdot \vec{x})$ \quad für alle  $\alpha,\beta \in K$,  $\vec{x} \in V$.

            Beachten Sie, dass der Operator ``$\cdot$'', der hier in dem Ausdruck $(\alpha \cdot \beta)$ auftritt, 
            die Multiplikation in dem Körper $K$ bezeichnet, während alle anderen Auftreten des Operators ``$\cdot$'' 
            die Skalar-Multiplikation bezeichnen.  

            Dieses Gesetz wird als das \blue{Assoziativ-Gesetz} bezeichnet.  Es drückt
            aus, dass die Multiplikation in dem Körper $K$ mit der Skalar-Multiplikation
            verträglich ist.
      \item $(\alpha + \beta) \cdot \vec{x} = \alpha \cdot \vec{x} + \beta \cdot \vec{x}$ \quad für alle  $\alpha,\beta \in K$,  $\vec{x} \in V$.

            Beachten Sie, dass der Operator ``$+$'', der  hier in dem Ausdruck $(\alpha + \beta)$
            auftritt, die Addition in dem Körper $K$ bezeichnet, während der
            Operator ``$+$'' in dem Ausdruck auf der rechten Seite dieser Gleichung die 
            Addition in der Gruppe $\langle V, \vec{0}, + \rangle$ bezeichnet.  
      \item $\alpha \cdot (\vec{x} + \vec{y}) = \alpha \cdot \vec{x} + \alpha \cdot \vec{y}$ \quad für alle $\alpha \in K$,  $\vec{x}, \vec{y} \in V$.

            Die letzten beiden Gesetze werden als \blue{Distributiv-Gesetze}
            bezeichnet.  Sie zeigen, inwiefern die Skalar-Multiplikation mit der Addition im Vektor-Raum
            $\mathcal{V}$ und der Addition im Körper $K$ verträglich ist.
      \item $1 \cdot \vec{x} = \vec{x}$ \quad für alle $\vec{x} \in V$.  

            Dieses Gesetz drückt aus, dass das neutrale Element der Multiplikation des Körpers
            $K$ auch bezüglich der Skalar-Multiplikation ein neutrales Element ist. 
      \end{enumerate}
\end{enumerate} 

\remark
In allen Beispielen, die uns in dieser Vorlesung begegnen werden, ist $\mathbb{K}$ entweder der Körper der
reellen Zahlen oder der Körper der komplexen Zahlen.  \eox 

Ist $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$  ein $\mathbb{K}$-Vektor-Raum, so bezeichnen wir die Elemente der Menge
$V$ als \blue{Vektoren}, während die Elemente aus dem Körper $\mathbb{K}$ 
\blue{Skalare} genannt werden.  Den Körper $\mathbb{K}$ nennen wir den
\blue{Skalaren-Körper} des Vektor-Raums $\mathcal{V}$.  
\eoxs
\end{Definition}

\remark
Es ist in der Literatur üblich, Vektoren von Skalaren durch Fettdruck zu unterscheiden.  
Da aber an der Tafel ein Fettdruck kaum möglich ist, habe ich mich dazu entschlossen, 
Vektoren durch Pfeilen zu kennzeichnen.
\eoxs


\example
Für eine Menge $K$ haben wir die Menge $K^n$ als die Menge aller Listen der Länge $n$ definiert,
deren Elemente aus der Menge $K$ stammen.  Ist nun $\mathbb{K} = \langle K, 0, 1, +, \cdot\rangle$
ein Körper, so definieren wir zunächst
\\[0.2cm]
\hspace*{1.3cm}
$\vec{0} := \underbrace{[0, \cdots, 0]}_n$ .
\\[0.2cm]
Anschließend definieren wir eine Addition ``${\color{blue}{+}}$'' auf $K^n$ komponentenweise durch
\\[0.2cm]
\hspace*{1.3cm}
$[x_1, \cdots, x_n] {\color{blue}{+}} [y_1, \cdots, y_n] := [x_1 + y_1, \cdots, x_n + y_n]$.
\\[0.2cm]
Nun können Sie nachrechnen, dass mit diesen Definitionen das Tripel
\\[0.2cm]
\hspace*{1.3cm}
$\langle K^n, \vec{0}, {\color{blue}+}\rangle$
\\[0.2cm]
eine kommutative Gruppe ist.  Definieren wir weiter die Skalar-Multiplikation
${\color{blue}\cdot}$ durch
\\[0.2cm]
\hspace*{1.3cm}
$\alpha {\color{blue}{\cdot}} [x_1, \cdots, x_n] := [\alpha \cdot x_1, \cdots, \alpha \cdot x_n]$,
\\[0.2cm]
wobei in den Ausdrücken $\alpha \cdot x_i$ der Operator ``$\cdot$'' die Multiplikation in dem Körper $\mathbb{K}$ bezeichnet,
dann lässt sich mit etwas Rechenaufwand einsehen, dass das Paar
\\[0.2cm]
\hspace*{1.3cm}
$\mathbb{K}^n := \bigl\langle \langle K^n, \vec{0}, {\color{blue}{+}} \rangle, {\color{blue}{\cdot}} \bigr\rangle$ 
\\[0.2cm]
ein $\mathbb{K}$-Vektor-Raum ist.  Der Kürze halber werden wir in Zukunft einfach von $\mathbb{K}^n$ als Vektor-Raum reden, wobei wir dann in Wahrheit das obige Paar meinen. 
\eoxs

\exerciseStar
Beweisen Sie, dass die oben definierte Struktur $\mathbb{K}^n$ für einen beliebigen Körper
$\mathbb{K}$ ein $\mathbb{K}$-Vektor-Raum ist. \eox 


Der Begriff des Vektor-Raums versucht, die algebraischen Eigenschaften der Struktur $\mathbb{K}^n$
axiomatisch zu erfassen.  Das ist deswegen nützlich, weil es neben dem Vektor-Raum 
$\mathbb{K}^n$ noch viele andere Beispiele gibt, welche dieselbe algebraische
Struktur aufweisen.  


\example
Die Menge $\mathbb{R}^{\mathbb{R}}$ ist die Menge der Funktionen der Form
\\[0.2cm]
\hspace*{1.3cm}
 $f: \mathbb{R} \rightarrow \mathbb{R}$,
\\[0.2cm]
also die Menge aller Funktionen von $\mathbb{R}$ nach $\mathbb{R}$.
Definieren wir die Addition zweier Funktionen \blue{punktweise}, definieren wir für $f,g \in \mathbb{R}^{\mathbb{R}}$ also die
Funktion $f+g$ indem wir
\\[0.2cm]
\hspace*{1.3cm}
$(f+g)(x) := f(x) + g(x)$  \quad für alle $x \in \mathbb{R}$
\\[0.2cm]
setzen, so ist die so definierte Funktion $f + g$ wieder eine Funktion von
$\mathbb{R}$ nach $\mathbb{R}$.  Weiter definieren wir für ein $\alpha \in \mathbb{R}$ und $f
\in\mathbb{R}^{\mathbb{R}}$  die Funktion
$\alpha {\color{blue}{\cdot}} f$ als
\\[0.2cm]
\hspace*{1.3cm}
$(\alpha \blue{\cdot} f)(x) := \alpha \cdot f(x)$ \quad für alle $x \in \mathbb{R}$.
\\[0.2cm]
Dann ist auch  $\alpha \blue{\cdot} f$ eine Funktion von $\mathbb{R}$ nach $\mathbb{R}$.  
Schließlich definieren wir eine Funktion
 $\vec{0}:\mathbb{R} \rightarrow \mathbb{R}$, indem wir
\\[0.2cm]
\hspace*{1.3cm}
$\vec{0}(x) := 0$ \quad für alle $x \in \mathbb{R}$ 
\\[0.2cm]
setzen.  Offensichtlich  gilt $\vec{0} \in \mathbb{R}^{\mathbb{R}}$.  Nun können Sie
in einer zwar länglichen, aber geradlinigen Rechnung nachprüfen, dass die so definierte Struktur
\\[0.2cm]
\hspace*{1.3cm}
$\bigl\langle \langle \mathbb{R}^{\mathbb{R}}, \vec{0}, + \rangle, \cdot \bigr\rangle$
\\[0.2cm]
ein $\mathbb{R}$-Vektor-Raum ist.  Das folgt letztlich daraus, dass das Assoziativ-Gesetz und das
Distributiv-Gesetz für reelle Zahlen 
gilt.
 \eoxs

\example
Es sei $\mathbb{K} = \langle K, 0,1,+,\cdot\rangle$ ein Körper.  Dann definieren wir $K^\mathbb{N}$ als die Menge aller
\blue{Folgen} mit Elementen aus $K$.  Eine Folge $x$ mit Elementen auf $K$ ist dabei eine Funktion von der
Menge der natürlichen Zahlen $\mathbb{N}$ in die Menge $K$:
\\[0.2cm]
\hspace*{1.3cm}
$x: \mathbb{N} \rightarrow K$.
\\[0.2cm]
Wir schreiben $x_n$ an Stelle von $x(n)$ und schreiben die Folge $x$ dann in der Form $\bigl(x_n\bigr)_{n\in\mathbb{N}}$.
Definieren wir für zwei Folgen
$\bigl(x_n\bigr)_{n\in\mathbb{N}}$ und $\bigl(y_n\bigr)_{n\in\mathbb{N}}$ die Summe durch
\\[0.2cm]
\hspace*{1.3cm}
$\bigl(x_n\bigr)_{n\in\mathbb{N}} {\color{blue}{+}} \bigl(y_n\bigr)_{n\in\mathbb{N}} := \bigl(x_n + y_n\bigr)_{n\in\mathbb{N}}$ 
\\[0.2cm]
und die Skalar-Multiplikation durch
\\[0.2cm]
\hspace*{1.3cm}
$\alpha {\color{blue}{\cdot}} \bigl(x_n\bigr)_{n\in\mathbb{N}} := \bigl(\alpha \cdot x_n \bigr)_{n\in\mathbb{N}}$
\\[0.2cm]
und definieren wir $\vec{0}$ als die Folge $(0)_{n\in\mathbb{N}}$, also als die Folge,
deren sämtliche Glieder den Wert $0$ haben, so lässt sich zeigen, dass die Struktur
 $\bigl\langle\langle K^\mathbb{N}, \vec{0}, {\color{blue}{+}}\rangle, {\color{blue}{\cdot}}\rangle$  ein Vektor-Raum ist.
\eoxs


\exercise
Es sei $\bigl\langle \langle V, \vec{0}, +\rangle, \cdot\bigr\rangle$ ein $\mathbb{K}$-Vektor-Raum.  Beweisen Sie:
\renewcommand{\labelenumi}{(\alph{enumi})}
\begin{enumerate}
\item $0 \cdot \vec{x} = \vec{0}$ \quad für alle $\vec{x} \in V$,
\item $\forall \alpha \in \mathbb{K}: \forall \vec{x} \in V: \bigl(\alpha \cdot \vec{x} = \vec{0} \rightarrow \alpha = 0 \vee \vec{x} = \vec{0}\bigr)$,
\item $(-1) \cdot \vec{x} = -\vec{x}$ \quad für alle $\vec{x} \in V$,

      wobei hier mit $-\vec{x}$ das additive Inverse von $x$ in der Gruppe $\langle V, \vec{0}, +\rangle$
      bezeichnet wird. 
      \eoxs
\end{enumerate}
\renewcommand{\labelenumi}{\arabic{enumi}.}

\section{Basis und Dimension}
In diesem Abschnitt führen wir den für die Theorie der Vektor-Räume zentralen Begriff
der \blue{Dimension}
ein.  Dazu definieren wir zunächst, was wir unter einem \blue{Erzeugenden-System}
verstehen und wann eine Menge von Vektoren \blue{linear unabhängig} ist.

\begin{Definition}[Linear-Kombination] \lb
Es sei $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$ ein $\mathbb{K}$-Vektor-Raum.  Ein Vektor $\vec{x} \in V$ ist eine
\blue{Linear-Kombination} der Vektoren $\vec{y}_1, \cdots, \vec{y}_n \in V$ genau dann, wenn es Skalare
$\alpha_1, \cdots, \alpha_n \in \mathbb{K}$ gibt, so dass die Gleichung
\\[0.2cm]
\hspace*{1.3cm}
$\vec{x} = \alpha_1 \cdot \vec{y}_1 + \cdots + \alpha_n \cdot \vec{y}_n$
\\[0.2cm]
gilt.  Wir setzen dabei stillschweigend voraus, dass die Vektoren $\vec{y}_i$ alle \red{paarweise verschieden} sind.
Die obige Gleichung werden wir in Zukunft der Kürze auch in der Form
\\[0.2cm]
\hspace*{1.3cm}
$\ds \vec{x} = \sum\limits_{i=1}^n \alpha_i \cdot \vec{y}_i$
\\[0.2cm]
schreiben.
\eoxs
\end{Definition}

\example
Im $\mathbb{R}^3$ definieren wir
\\[0.2cm]
\hspace*{1.3cm}
$\vec{y}_1 := [1, 0, 2]$, \quad  $\vec{y}_2 := [1, 2, 0]$, \quad  $\vec{y}_3 := [0, -1, 3]$  \quad und \quad  $\vec{x} := [3, 1, 11]$.
\\[0.2cm]
Dann ist $\vec{x}$ eine Linear-Kombination der Vektoren $\vec{y}_1$, $\vec{y}_2$, $\vec{y}_3$, denn es gilt
\\[0.2cm]
\hspace*{1.3cm}
$\vec{x} = 1 \cdot \vec{y}_1 + 2 \cdot \vec{y}_2 + 3 \cdot \vec{y}_3$.  \eoxs
\pagebreak

\begin{Definition}[linear unabhängig] \lb
Es sei $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$ ein $\mathbb{K}$-Vektor-Raum.  
Eine $n$-elementige Menge $B = \bigl\{ \vec{x}_1, \cdots, \vec{x}_n \bigr\} \subseteq V$ ist
\blue{linear unabhängig} genau dann, wenn  
\\[0.2cm]
\hspace*{1.3cm}
$\ds \sum\limits_{i=1}^n \alpha_i \cdot \vec{x}_i = \vec{0} \;\Rightarrow\; \forall i \in \{1,\cdots,n\}: \alpha_i = 0$
\\[0.2cm]
gilt.  Mit anderen Worten:  Der Nullvektor $\vec{0}$ lässt sich nur als die sogenannte
\blue{triviale Linear-Kombination} aus Vektoren der Menge $B$ darstellen.  Demgegenüber heißt eine
$n$-elementige Menge $B = \bigl\{ \vec{x}_1, \cdots, \vec{x}_n \bigr\}$ \blue{linear abhängig}
genau dann, wenn $B$ nicht linear unabhängig ist.  In 
diesem Fall gibt es dann Skalare $\alpha_1,\cdots,\alpha_n \in \mathbb{K}$, so dass einerseits
\\[0.2cm]
\hspace*{1.3cm}
$\ds\sum\limits_{i=1}^n \alpha_i \cdot \vec{x}_i = \vec{0}$, \quad aber andererseits auch \quad
$\exists i \in \{1,\cdots,n\}: \alpha_i \,\not=\, 0$
\\[0.2cm]
gilt.  
\eoxs
\end{Definition}

\remark
Aus der Voraussetzung, dass die Menge $B = \bigl\{ \vec{x}_1, \cdots, \vec{x}_n \bigr\}$ aus $n$ Elementen
besteht, folgt sofort, dass die Vektoren  $\vec{x}_1, \cdots, \vec{x}_n$ paarweise verschieden sind.

\example
Im $\mathbb{R}^3$ definieren wir
\\[0.2cm]
\hspace*{1.3cm}
$\vec{y}_1 := [1, 0, 2]$, \quad  $\vec{y}_2 := [1, 2, 0]$ \quad und \quad $\vec{y}_3 := [0, -1, 3]$.
\\[0.2cm]
Dann ist die Menge $B := \{ \vec{y}_1, \vec{y}_2, \vec{y}_3 \}$
linear unabhängig.  Zum Beweis dieser Behauptung nehmen wir zunächst an, dass es $\alpha_1$,
$\alpha_2$ und $\alpha_3$, gibt, so dass
\\[0.2cm]
\hspace*{1.3cm}
$\vec{0} = \alpha_1 \cdot [1,0,2] + \alpha_2 \cdot [1,2,0] + \alpha_3 \cdot [0,-1,3]$
\\[0.2cm]
gilt.  Ersetzen wir $\vec{0}$ durch die Liste $[0,0,0]$ und rechnen die rechte Seite
dieser Gleichung aus, so erhalten wir die Gleichung
\\[0.2cm]
\hspace*{1.3cm}
$[0,0,0] = [\alpha_1  + \alpha_2, 2 \cdot \alpha_2 - \alpha_3, 2 \cdot \alpha_1 + 3 \cdot \alpha_3]$.
\\[0.2cm]
Die drei Komponenten der Vektoren auf der linken und der rechten Seite dieser Gleichung müssen
gleich sein.  Damit müssen die drei Gleichungen
\\[0.2cm]
\hspace*{1.3cm}
$0 = \alpha_1 + \alpha_2$, \quad $0 = 2 \cdot \alpha_2 - \alpha_3$ \quad und \quad $0 = 2 \cdot \alpha_1 + 3 \cdot \alpha_3$
\\[0.2cm]
gelten.  Aus der zweiten Gleichung folgt nun $\alpha_3 = 2 \cdot \alpha_2$, während aus der ersten
Gleichung $\alpha_1 = - \alpha_2$ folgt.  Ersetzen wir nun in der letzten Gleichung 
$\alpha_1$ durch $-\alpha_2$ und $\alpha_3$ durch $2 \cdot \alpha_2$, so erhalten wir die neue Gleichung
\\[0.2cm]
\hspace*{1.3cm}
$0 = 2 \cdot (- \alpha_2) + 3 \cdot 2 \cdot \alpha_2$,
\\[0.2cm]
die wir auch als $0 = 4 \cdot \alpha_2$ schreiben können.  Daraus folgt aber sofort $\alpha_2 = 0$
und das impliziert dann auch $\alpha_1 = 0$ und $\alpha_3 = 0$.  Damit haben wir gezeigt, dass die drei
Vektoren $\vec{y}_1$, $\vec{y}_2$, $\vec{y}_3$ sich nur {\color{blue}trivial} zu dem Null-Vektor
$\vec{0}$ kombinieren lassen.  Folglich ist die Menge $B$ linear unabhängig.
\eoxs

\begin{Definition}[Erzeugenden-System]
  Es sei $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$ ein $\mathbb{K}$-Vektor-Raum 
  und die Menge $B =  \bigl\{ \vec{x}_1, \cdots, \vec{x}_n \bigr\} \subseteq V$ enthalte $n$ Elemente.  Die
  Menge $B$ ist ein 
  \blue{Erzeugenden-System} des Vektor-Raums $\mathcal{V}$ genau dann, wenn sich jeder Vektor 
  $\vec{x} \in V$ als Linear-Kombination von Vektoren aus $B$ schreiben lässt. 
  Als Formel schreibt sich dies wie folgt:
  \\[0.2cm]
  \hspace*{1.3cm}
  $\ds\forall \vec{x} \in V: \exists \alpha_1, \cdots, \alpha_n \in \mathbb{K}: \vec{x} = \sum\limits_{i=1}^n \alpha_i \cdot \vec{y}_i
  $. \eoxs
\end{Definition}

Je mehr Elemente ein Erzeugenden-System hat, um so einfacher ist es, daraus andere Vektoren zu erzeugen.
Besonders interessant sind diejenigen Erzeugenden-Systeme, die möglichst wenige Elemente haben, die also
bezüglich der Anzahl der Elemente \blue{minimal} sind.  Dies führt zu der folgenden zentralen Definition.

\begin{Definition}[Basis]
  Es sei $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$ ein $\mathbb{K}$-Vektor-Raum und $B$ sei eine endliche Teilmenge von $V$.  Dann ist $B$ eine
  \blue{Basis} von $\mathcal{V}$, wenn das Folgende gilt:
  \begin{enumerate}
  \item $B$ ist ein Erzeugenden-System von $\mathcal{V}$ und
  \item $B$ ist linear unabhängig.  \eoxs
  \end{enumerate}
\end{Definition}

\remark
Wir haben hier die Begriffe \blue{lineare Unabhängigkeit}, \blue{Erzeugenden-System} und \blue{Basis} nur für
endliche Mengen von Vektoren definiert.  Diese Begriffe können auch so verallgemeinert werden, dass Sie für
unendliche Mengen von Vektoren gelten.  Das führt aber zu einer etwas umständlicheren Theorie.  Daher
verzichten wir darauf.
\eox

\noindent
Der nächste Satz zeigt, dass eine Basis eine \red{maximale} Menge linear unabhängiger Vektoren ist.

\begin{Satz}
  Es sei $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$ 
  ein $\mathbb{K}$-Vektor-Raum und $B$ sei eine Basis von $\mathcal{V}$.  Ist $\vec{x} \in V \backslash B$,
  so ist die Menge $B \cup \{ \vec{x} \}$ linear abhängig.
\end{Satz}

\proof
Es sei $B = \bigl\{ \vec{y}_1,\cdots,\vec{y}_n \bigr\}$ und es gelte $\textsl{card}(B) = n$.
Da $B$ eine Basis ist, ist $B$ insbesondere auch ein Erzeugenden-System von $\mathcal{V}$.  Damit gibt es 
Skalare $\alpha_1, \cdots,\alpha_n \in \mathbb{K}$,  so dass
\\[0.2cm]
\hspace*{1.3cm}
$\vec{x} = \alpha_1 \cdot \vec{y}_1 + \cdots + \alpha_n \cdot \vec{y}_n$
\\[0.2cm]
gilt.  Da  $\textsl{card}(B) = n$ ist, sind die Vektoren $\vec{y}_i$ paarweise verschieden.
Stellen wir die obige Gleichung für $\vec{x}$ zu der Gleichung
\\[0.2cm]
\hspace*{1.3cm}
$\vec{0} = (-1) \cdot \vec{x} + \alpha_1 \cdot \vec{y}_1 + \cdots + \alpha_n \cdot \vec{y}_n$
\\[0.2cm]
um, so haben wir eine nicht-triviale Linear-Kombination des Null-Vektors aus Vektoren der Menge 
$B \cup \{ \vec{x} \}$ gefunden.  Dies zeigt, dass die Menge $B \cup \{ \vec{x} \}$ linear abhängig
ist. \qeds

\exercise
Überlegen Sie, an welcher Stelle die Voraussetzung $\vec{x} \not\in B$ in dem obigen Beweis benutzt wird!
\eox

\noindent
Der letzte Satz lässt sich in dem folgenden Sinne umkehren.

\begin{Satz}
  Es sei $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$ ein $\mathbb{K}$-Vektor-Raum 
  und $B \subseteq V$.  Falls $B$ eine \blue{maximale} linear 
  unabhängige Teilmenge von $V$ ist, falls also gilt:
  \begin{enumerate}
  \item $B$ ist linear unabhängig und
  \item für alle Vektoren $\vec{x} \in V \backslash B$ ist die Menge $B \cup \{ \vec{x} \}$
        linear abhängig,
  \end{enumerate}
  dann ist $B$ schon eine Basis von $\mathcal{V}$.
\end{Satz}

\proof
Es sei $B = \bigl\{ \vec{y}_1, \cdots, \vec{y}_n \bigr\}$ und $\textsl{card}(B) = n$.
Wir müssen nur noch zeigen, dass $B$ ein Erzeugenden-System von $\mathcal{V}$ ist.  Dazu ist nachzuweisen,
dass sich jeder Vektor $\vec{x} \in V$ als Linear-Kombination von Vektoren aus $B$ schreiben
lässt.  Wir unterscheiden zwei Fälle:
\begin{enumerate}
\item $\vec{x} \in B$, also beispielsweise $\vec{x} = \vec{y}_k$ für ein $k \in \{1,\cdots,n\}$.

      In diesem Fall setzen wir  $\alpha_k := 1$ und $\alpha_i := 0$ für $i \not= k$.  Damit
      gilt offenbar
      \\[0.2cm]
      \hspace*{1.3cm}
      $\vec{x} = \vec{y}_k = \sum\limits_{i=1}^n \alpha_i \cdot \vec{y}_i$
      \\[0.2cm]
      und wir haben die gesuchte Linear-Kombination gefunden.
\item $\vec{x} \not\in B$.

      Nach Voraussetzung ist die Menge $B \cup \{ \vec{x} \}$ linear abhängig.  Damit lässt sich
      der Null-Vektor als nicht-triviale Linear-Kombination von Vektoren aus $B \cup \{\vec{x}\}$
      schreiben.  Nun gibt es zwei Möglichkeiten:
      \begin{enumerate}
      \item Der Vektor $\vec{x}$ wird bei dieser Linear-Kombination gar nicht benötigt.
            Dann hätten wir aber eine nicht-triviale Linear-Kombination des Null-Vektors aus
            Vektoren der Menge $B$.  Da die Menge $B$ nach Voraussetzung linear unabhängig ist,
            kann dieser Fall nicht eintreten.
      \item Der Vektor $\vec{x}$ tritt in der nicht-trivialen Linear-Kombination des
            Null-Vektors auf.  Es gibt dann Skalare $\alpha_1, \cdots, \alpha_n, \alpha_{n+1}$, so dass 
            \\[0.2cm]
            \hspace*{1.3cm}
            $\vec{0} = \alpha_1 \cdot \vec{y}_1 + \cdots + \alpha_n \cdot \vec{y}_n + \alpha_{n+1} \cdot \vec{x}$
            \\[0.2cm]
            gilt.  Hierbei muss $\alpha_{n+1} \not=0$ gelten, denn sonst würde $\vec{x}$ in der
            Linear-Kombination gar nicht benötigt und diesen Fall haben wir ja bereits
            ausgeschlossen.  Damit 
            können wir die obige Gleichung zu
            \\[0.2cm]
            \hspace*{1.3cm}
            $\vec{x} = -\bruch{\alpha_1}{\alpha_{n+1}} \cdot \vec{y}_1 - \cdots - \bruch{\alpha_n}{\alpha_{n+1}} \cdot \vec{y}_n$
            \\[0.2cm] 
            umstellen.  Diese Gleichung zeigt, dass $\vec{x}$ sich als Linear-Kombination von Vektoren aus
            $B$ schreiben lässt und das war zu zeigen. 
      \end{enumerate}
\end{enumerate}
Insgesamt haben wir jetzt gezeigt, dass sich jeder Vektor $\vec{x}\in V$ als Linear-Kombination
von Vektoren aus $B$ schreiben lässt und damit ist $B$ ein Erzeugenden-System von $V$.  \qed

Die letzten beiden Sätze lassen sich dahingehen zusammenfassen, dass eine Menge
$B \subseteq V$ genau dann eine Basis von $V$ ist, wenn $B$ eine maximale linear unabhängige
Teilmenge von $V$ ist.  Die nächsten beiden Sätze zeigen, dass sich eine Basis auch als minimales
Erzeugenden-System charakterisieren lässt.

\begin{Satz}
  Es sei $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$ ein
  $\mathbb{K}$-Vektor-Raum und $B$ sei eine Basis von $\mathcal{V}$.  Ist $\vec{x} \in B$,
  so ist die Menge $B \backslash \{ \vec{x} \}$ kein Erzeugenden-System von $\mathcal{V}$.
\end{Satz}

\proof
Es sei $B = \bigl\{ \vec{y}_1, \cdots, \vec{y}_n \bigr\}$ und $\textsl{card}(B) = n$.  O.B.d.A.~sei $\vec{x} = \vec{y}_n$.
Wir führen den Beweis indirekt und nehmen an, dass die Menge
\\[0.2cm]
\hspace*{1.3cm}
$B \backslash \{ \vec{x} \} = \bigl\{ \vec{y}_1, \cdots, \vec{y}_{n-1}\bigr\}$  
\\[0.2cm]
ein
Erzeugenden-System von $\mathcal{V}$ ist.  Dann müsste sich insbesondere auch der Vektor $\vec{x}$ als
Linear-Kombination von Vektoren aus  $B \backslash \{ \vec{x} \}$ schreiben lassen.  Es gäbe dann
also Skalare $\alpha_1, \cdots, \alpha_n \in \mathbb{K}$, so dass
\\[0.2cm]
\hspace*{1.3cm}
$\vec{x} = \vec{y}_n = \alpha_1 \cdot \vec{y_1} + \cdots + \alpha_{n-1} \cdot \vec{y}_{n-1}$
\\[0.2cm]
gelten würde.  Diese Gleichung können wir zu
\\[0.2cm]
\hspace*{1.3cm}
$\vec{0} =  \alpha_1 \cdot \vec{y_1} + \cdots + \alpha_{n-1} \cdot \vec{y}_{n-1} + (-1) \cdot \vec{y}_n$
\\[0.2cm]
umstellen.  Dies widerspricht der Tatsache, dass die Menge $B$ als Basis insbesondere linear unabhängig ist. \qed

Der letzte Satz zeigt, dass eine Basis ein \blue{minimales Erzeugenden-System} des Vektor-Raums $\mathcal{V}$
ist.  Wie wir jetzt sehen werden, lässt sich dieser Satz auch umkehren.

\begin{Satz}
  Es sei $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$ ein $\mathbb{K}$-Vektor-Raum 
  und $B \subseteq V$.  Falls $B$ eine \blue{minimales Erzeugenden-System}
  von $\mathcal{V}$ ist, falls also gilt:
  \begin{enumerate}
  \item $B$ ist ein Erzeugenden-System von $\mathcal{V}$ und
  \item für alle Vektoren $\vec{x} \in B$ ist die Menge $B \backslash \{ \vec{x} \}$
        kein Erzeugenden-System von $\mathcal{V}$,
  \end{enumerate}
  dann ist $B$ schon eine Basis von $\mathcal{V}$.
\end{Satz}

\proof
Es sei $B = \bigl\{ \vec{y}_1, \cdots, \vec{y}_n \bigr\}$ und $\textsl{card}(B) = n$.
Da die Menge $B$ nach Voraussetzung bereits ein Erzeugenden-System von $\mathcal{V}$ ist, müssen wir
lediglich zeigen, dass $B$ linear unabhängig ist.  Wir führen auch diesen Beweis als
Widerspruchsbeweis und nehmen an, dass $B$ linear abhängig wäre.  Mit dieser Annahme finden wir eine
nicht-triviale Linear-Kombination des Null-Vektors mit Hilfe von Vektoren aus $B$, wir finden also
Skalare $\alpha_1, \cdots, \alpha_n \in \mathbb{K}$, so dass
\\[0.2cm]
\hspace*{1.3cm}
$\vec{0} =  \alpha_1 \cdot \vec{y}_1 + \cdots + \alpha_n \cdot \vec{y}_n$
\\[0.2cm]
gilt, wobei wenigstens einer der Skalare $\alpha_k$ von $0$ verschieden ist.  O.B.d.A. sei $\alpha_n \not= 0$. 
Dann können wir die obige Gleichung zu 
\\[0.2cm]
\hspace*{1.3cm}
$\ds(-\alpha_n) \cdot \vec{y_n} = \sum\limits_{i=1}^{n-1} \alpha_i \cdot \vec{y}_i$
\\[0.2cm]
umstellen.  Da $\alpha_n \not= 0$ ist, können wir durch $\alpha_i$ teilen und finden
\\[0.2cm]
\hspace*{1.3cm}
$\ds \vec{y}_n = \sum\limits_{i=1}^{n-1} \bruch{-\alpha_i}{\alpha_n} \cdot \vec{y}_i$.
\\[0.2cm]
Die letzte Gleichung zeigt, dass sich $\vec{y}_n$ als Linear-Kombination der Vektoren
$\vec{y}_1, \cdots, \vec{y}_{n-1}$, schreiben lässt.  Wir werden jetzt zeigen, dass damit dann auch die Menge
$B \backslash \{ \vec{y_n} \}$ ein Erzeugenden-System von $V$ ist.  Sei dazu $\vec{x}$ ein
beliebiger Vektor aus $V$.  Da $B$ ein Erzeugenden-System von $\mathcal{V}$ ist, gibt es 
Skalare $\beta_1, \cdots, \beta_n \in \mathbb{K}$, so dass
\\[0.2cm]
\hspace*{1.3cm}
$\ds \vec{x} = \sum\limits_{i=1}^n \beta_i \cdot \vec{y}_i$
\\[0.2cm]
gilt.  Berücksichtigen wir das Ergebnis, das wir für $\vec{y}_n$ gefunden haben, so können wir die obige
Gleichung wie folgt umschreiben:
\\[0.2cm]
\hspace*{1.3cm}
$\ds\vec{x} = \sum\limits_{i=1}^{n-1} \beta_i \cdot \vec{y}_i + 
              \beta_n \cdot \sum\limits_{i=1}^{n-1} \bruch{-\alpha_i}{\alpha_n} \cdot \vec{y}_i
            = \sum\limits_{i=1}^{n-1} \left(\beta_i - \beta_n \cdot \bruch{\alpha_i}{\alpha_n}\right) \cdot \vec{y}_i
$
\\[0.2cm]
Damit haben wir $\vec{x}$ als Linear-Kombination von Vektoren der Menge 
$B \backslash \{ \vec{y}_n \}$ schreiben können.  Dies zeigt, dass die Menge
$B \backslash \{ \vec{y}_n \}$ bereits ein Erzeugenden-System von $\mathcal{V}$ ist und steht im
Widerspruch dazu, dass $B$ ein minimales Erzeugenden-System ist.  Dieser Widerspruch zeigt, dass die
Annahme, dass $B$ linear abhängig ist, falsch sein muss. \qeds

\exercise
Es sei $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$ ein $\mathbb{K}$-Vektor-Raum und es gelte $B := \{ \vec{x}_1, \cdots, \vec{x}_n \} \subseteq V$.
Zeigen Sie:  $B$ ist genau dann eine Basis von $\mathcal{V}$, wenn sich jeder Vektor $\vec{y} \in V$ in
eindeutiger Weise als Linear-Kombination der Vektoren aus $B$ schreiben lässt.
\eoxs

\begin{Lemma}[Basis-Austausch-Lemma]
  Es gelte:
  \begin{enumerate}
  \item $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$ ist ein $\mathbb{K}$-Vektor-Raum, 
  \item $B = \{ \vec{y}_1, \cdots, \vec{y}_n \}$ eine Basis von $\mathcal{V}$,
  \item $\vec{x} = \alpha_1 \cdot \vec{y}_1 + \cdots + \alpha_n \cdot \vec{y}_n$ und $\alpha_k \not= 0$ 
  \end{enumerate}
  Dann ist die Menge
\\[0.2cm]
\hspace*{1.3cm}
$(B \backslash \{ \vec{y}_k \}) \cup \{\vec{x}\} =
  \{ \vec{y}_1, \cdots \vec{y}_{k-1}, \vec{x}, \vec{y}_{k+1},  \cdots, \vec{n}\}
$
\\[0.2cm]
wieder eine Basis von $\mathcal{V}$.
Wir können also den Vektor $\vec{x}$ gegen den Vektor $\vec{y}_k$ aus der Basis $B$ austauschen.
\end{Lemma}

\proof
Da es auf die Reihenfolge der Vektoren in der Menge $B$ nicht ankommt, können wir o.B.d.A.~annehmen, dass $k=n$
gilt.  Dadurch vereinfacht sich im Folgenden die Schreibweise.  Da $\alpha_n \not= 0$ ist, können wir die
Gleichung
\begin{equation}
  \label{eq:atl1}
  \vec{x} = \alpha_1 \cdot \vec{y}_1 + \cdots + \alpha_n \cdot \vec{y}_n
\end{equation}
nach dem Vektor $\vec{y}_n$ auflösen und erhalten
\begin{equation}
  \label{eq:atl2}
  \ds \vec{y}_n = \frac{1}{\alpha_n} \cdot \vec{x} -
  \frac{\alpha_1}{\alpha_n} \cdot \vec{y}_1 - \cdots - \frac{\alpha_{n-1}}{\alpha_n} \cdot \vec{y}_{n-1}.
\end{equation}
Den Rest des Beweises spalten wir in zwei Teile auf.
\begin{enumerate}
\item Wir zeigen, dass $\{ \vec{y}_1, \cdots \vec{y}_{n-1}, \vec{x} \}$ linear unabhängig ist.
      Dazu nehmen wir an, dass
      \begin{equation}
        \label{eq:atl3}
        \lambda_1 \cdot \vec{y}_1 + \cdots + \lambda_{n-1} \cdot \vec{y}_{n-1} + \lambda_n \cdot \vec{x} = \vec{0}        
      \end{equation}
      ist.  Wir müssen dann zeigen, dass
      \begin{equation}
        \label{eq:atl4}
      \forall i \in \{1,\cdots,n\}:\lambda_i = 0        
      \end{equation}
      gilt.  Ersetzen wir in Gleichung (\ref{eq:atl3}) den Vektor $\vec{x}$ durch die Linear-Kombination aus
      Gleichung (\ref{eq:atl1}), so erhalten wir
      \\[0.2cm]
      \hspace*{1.3cm}
      $\lambda_1 \cdot \vec{y}_1 + \cdots + \lambda_{n-1} \cdot \vec{y}_{n-1} + \lambda_n \cdot (\alpha_1 \cdot \vec{y}_1 + \cdots + \alpha_n \cdot \vec{y}_n) = \vec{0}$,
      \\[0.2cm]
      was wir noch zu
      \begin{equation}
        \label{eq:atl5}
        (\lambda_1 + \lambda_n \cdot \alpha_1) \cdot \vec{y}_1 + \cdots +
        (\lambda_{n-1} + \lambda_n \cdot \alpha_{n-1}) \cdot \vec{y}_{n-1} +
        \lambda_n \cdot \alpha_n \cdot \vec{y}_n = \vec{0}
      \end{equation}
      umordnen können.  Da die Menge $B = \{ \vec{y}_1, \cdots, \vec{y}_n \}$ eine Basis ist, ist sie auch
      linear unabhängig und daher folgen aus Gleichung (\ref{eq:atl5}) die Gleichungen
      \\[0.2cm]
      \hspace*{1.3cm}
      $\lambda_1 + \lambda_n \cdot \alpha_1 = 0$, \quad $\cdots$, \quad $\lambda_{n-1} + \lambda_n \cdot \alpha_{n-1} = 0 $
      \quad und \quad $\lambda_n \cdot \alpha_n = 0$.
      \\[0.2cm]
      Da nach Voraussetzung $\alpha_n \not= 0$ ist, folgt aus der Gleichungen $\lambda_n \cdot \alpha_n = 0$
      sofort $\lambda_n = 0$ und damit vereinfachen sich die anderen Gleichungen zu
      \\[0.2cm]
      \hspace*{1.3cm}
      $\lambda_1 = 0$, \quad $\cdots$, \quad $\lambda_{n-1} = 0$,
      \\[0.2cm]
      so dass wir insgesamt die Gleichungen (\ref{eq:atl4}) gezeigt haben.  Damit ist die lineare Unabhängigkeit
      der Menge  $\{ \vec{y}_1, \cdots \vec{y}_{n-1}, \vec{x} \}$ nachgewiesen.  $\green{\surd}$
\item Wir zeigen, dass $\{ \vec{y}_1, \cdots \vec{y}_{n-1}, \vec{x} \}$ ein Erzeugenden-System ist.  Dazu
      nehmen wir an, dass $\vec{z}$ ein beliebiger Vektor aus der $V$ ist.  Wir müssen dann $\vec{z}$ als
      Linear-Kombination von Vektoren aus $\{ \vec{y}_1, \cdots \vec{y}_{n-1}, \vec{x} \}$ darstellen.
      Zunächst wissen wir, dass die Menge $\{ \vec{y}_1, \cdots \vec{y}_{n-1}, \vec{y}_n \}$ eine Basis on
      $\mathcal{V}$ ist.  Daher können wir $\vec{z}$ als Linear-Kombination dieser Vektoren darstellen.
      Damit gibt es Skalare $\beta_1, \cdots, \beta_n \in \mathbb{K}$, so dass
      \\[0.2cm]
      \hspace*{1.3cm}
      $\vec{z} = \beta_1 \cdot \vec{y}_1 + \cdots \beta_n \cdot \vec{y}_n$
      \\[0.2cm]
      gilt.  In dieser Gleichung ersetzen wir $\vec{y}_n$ durch den Wert, den wir in Gleichung (\ref{eq:atl2})
      erhalten haben.  Das liefert die Gleichung
      \\[0.2cm]
      \hspace*{1.3cm}
      $\ds \vec{z} = \beta_1 \cdot \vec{y}_1 + \cdots + \beta_{n-1} \cdot \vec{y}_{n-1} +
      \beta_n \cdot \left(\frac{1}{\alpha_n} \cdot \vec{x} -
      \frac{\alpha_1}{\alpha_n} \cdot \vec{y}_1 - \cdots - \frac{\alpha_{n-1}}{\alpha_n} \cdot \vec{y}_{n-1}\right)$.      
      \\[0.2cm]
      Gruppieren wir die Terme um, so erhalten wir
      \\[0.2cm]
      \hspace*{1.3cm}
      $\ds \vec{z} = \left(\beta_1 - \beta_n \cdot \frac{\alpha_1}{\alpha_n}\right) \cdot \vec{y}_1 + \cdots +
                     \left(\beta_{n-1} - \beta_n \cdot \frac{\alpha_{n-1}}{\alpha_n} \right) \cdot \vec{y}_{n-1} +
                     \frac{\beta_n}{\alpha_n} \cdot \vec{x}
      $.      
      \\[0.2cm]
      Das ist aber eine Linear-Kombination von $\vec{z}$ aus den Vektoren der Menge
      $\{ \vec{y}_1, \cdots \vec{y}_{n-1}, \vec{x} \}$ und damit ist klar, dass diese Menge
      ein Erzeugenden-System ist. \qed
\end{enumerate}


Das gerade bewiesene Lemma zeigt uns, dass wir in einer Basis einen beliebigen von dem Nullvektor
verschiedenen Vektor $\vec{x}$ 
gegen einen Vektor der Basis austauschen können.  Der nächste Satz verallgemeinert diesen Tatbestand
und zeigt, dass wir 
in einer Basis $B$ eine linear unabhängige Menge $U$ gegen eine Teilmenge $W$ von $B$ austauschen
können, welche dieselbe Anzahl an Elementen hat wie $U$.
\pagebreak

\begin{Satz}[Basis-Austausch-Satz]
  Es gelte:
  \begin{enumerate}
  \item $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$ ist ein $\mathbb{K}$-Vektor-Raum,
  \item $B = \{ \vec{y}_1, \cdots, \vec{y}_m \}$ ist eine Basis von $\mathcal{V}$,
  \item $U = \{ \vec{x}_1, \cdots, \vec{x}_n \} \subseteq V$ ist linear unabhängig,
  \end{enumerate}
  Dann gibt es eine Teilmenge $W \subseteq B$, so dass gilt:
  \begin{enumerate}
  \item $\bigl(B \backslash W\bigr) \cup U$ ist eine Basis von V,
  \item $\textsl{card}(W) = \textsl{card}(U)$.
  \end{enumerate}
  Wir können also eine gegebene linear unabhängige Menge $U$ in eine gegebene Basis einbinden,
  indem wir eine Teilmenge $W$ von $B$ durch $U$ ersetzten.  Diese Teilmenge $W$ enthält dieselbe
  Anzahl von Elementen wie die Menge $U$.
\end{Satz}

\proof
Die Idee bei diesem Beweis besteht darin, dass wir die Elemente der Menge $U$ mit Hilfe
des Basis-Austausch-Lemmas sukzessive gegen Elemente der Menge $B$ austauschen.  Für jedes
Element $\vec{x}$ aus der Menge $U$ finden wir dabei ein $\vec{y}$ aus der Menge
$B$, so dass wir in der Basis $B$ das Element $\vec{y}$ durch $\vec{x}$ ersetzen können.
Um diese Argumentation formal wasserdicht zu machen, führen wir 
den exakten Beweis durch Induktion nach der Anzahl $n$ der Elemente der linear unabhängigen Menge $U$. 
\begin{enumerate}
\item[I.A.:] $n = 0$. 

             Dann gilt offenbar $U = \{\}$ und wir können $W := \{\}$ definieren.  Wegen
             \\[0.2cm]
             \hspace*{1.3cm}
             $\bigl(B \backslash W\bigr) \cup U = \bigl(B \backslash \{\}\bigr) \cup \{\} = B$ \quad und \quad
             $\textsl{card}(W) = \textsl{card}(\{\}) = \textsl{card}(U)$
             \\[0.2cm]
             ist dann nichts mehr zu zeigen, denn $B$ ist nach Voraussetzung eine Basis von $V$.
\item[I.S.:] $n \mapsto n+1$. 

             Es gilt jetzt $\textsl{card}(U) = n + 1$.
             Also hat $U$ die Form $U = \{ \vec{x}_1, \cdots, \vec{x}_n, \vec{x}_{n+1} \}$.
             Wir definieren 
             $U' := U \backslash \{ \vec{x}_{n+1} \} = \{ \vec{x}_1, \cdots, \vec{x}_n\}$.
             Damit folgt $\textsl{card}(U') = n$.  Nach Induktions-Voraussetzung
             finden wir daher eine Menge $W' \subseteq B$, so dass einerseits
             \\[0.2cm]
             \hspace*{1.3cm}
             $\textsl{card}(W')= \textsl{card}(U') = n$ 
             \\[0.2cm]
             und andererseits die Menge $\bigl(B \backslash W'\bigr) \cup U'$  eine Basis von $V$ ist.  Um die
             Dinge konkret zu machen, nehmen wir an, dass sich die Menge $B \backslash W'$ als
             \\[0.2cm]
             \hspace*{1.3cm}
             $B \backslash W' = \{ \vec{z}_1, \cdots, \vec{z}_{m-n} \}$.
             \\[0.2cm]
             schreiben lässt.  Da die Menge $\bigl(B \backslash W'\bigr) \cup U'$ als Basis auch ein
             Erzeugenden-System ist, können wir den Vektor $\vec{x}_{n+1}$ als 
             Linear-Kombination der Vektoren aus  $\bigl(B \backslash W'\bigr) \cup U'$ darstellen.  Diese
             Linear-Kombination hat die Form
             \\[0.2cm]
             \hspace*{1.3cm}
             $ \vec{x}_{n+1} = \beta_1 \cdot \vec{z}_1 + \cdots + \beta_{m-n} \cdot \vec{z}_{m-n} 
                              + \alpha_{1} \cdot \vec{x}_1 + \cdots + \alpha_n \cdot \vec{x}_n
             $
             \\[0.2cm]
             In dieser Linear-Kombination können nicht alle Koeffizienten $\beta_i$ der Vektoren aus der  $B \backslash W'$ den
             Wert $0$ haben, denn sonst würde der Vektor $\vec{x}_{n+1}$ sich als Linear-Kombination von
             Vektoren aus $\{\vec{x}_1,\cdots, \vec{x}_n \}$ und dann wäre die Menge
             $U = \{\vec{x}_1,\cdots, \vec{x}_n, \vec{x}_{n+1} \}$ sicher nicht linear unabhängig.  Wir finden
             also ein $k \in \{1,\cdots,m-n\}$, so dass der Koeffizient $\beta_k \not= 0$ ist.  Damit können
             wir das Basis-Austausch-Lemma auf die Basis $\bigl(B \backslash W'\bigr) \cup U'$ und den Vektor
             $\vec{x}_{n+1}$ anwenden und den Vektor $\vec{z}_k$ durch den Vektor $\vec{x}_{n+1}$ ersetzen.
             Definieren wir
             \\[0.2cm]
             \hspace*{1.3cm}
             $W := W' \cup \{ \vec{z}_k \}$
             \\[0.2cm]
             so gilt $(B \backslash W') \backslash \{\vec{z}_k\} = B \backslash W$ und die Menge
             \\[0.2cm]
             \hspace*{1.3cm}
             $(B \backslash W) \cup U' \cup \{\vec{x}_{n+1}\} = (B \backslash W) \cup U$
             \\[0.2cm]
             ist eine Basis von $\mathcal{V}$.  Offenbar gilt auch $\textsl{card}(W) = \textsl{card}(U) = n+1$.
             \qeds
\end{enumerate}

\begin{Korollar}
  Ist $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$ ein $\mathbb{K}$-Vektor-Raum, $B$ eine Basis von $\mathcal{V}$ und $U \subseteq V$ linear unabhängig,
  so gilt $\textsl{card}(U) \leq \textsl{card}(B)$.
\end{Korollar}

\proof
Der Basis-Austausch-Satz besagt, dass wir eine Teilmenge $W \subseteq B$ finden, so dass einerseits 
$\textsl{card}(W) = \textsl{card}(U)$ gilt und dass andererseits $(B\backslash W) \cup U$ eine Basis
von $B$ ist.  Aus $W \subseteq B$ folgt $\textsl{card}(W) \leq \textsl{card}(B)$ und 
wegen $\textsl{card}(W) = \textsl{card}(U)$ folgt die Behauptung. \qed

Haben wir zwei verschiedene Basen $B_1$ und $B_2$ eines Vektor-Raums $B$, so können wir mit dem letzten Korollar sowohl
$\textsl{card}(B_2) \leq \textsl{card}(B_1)$ als auch $\textsl{card}(B_1) \leq \textsl{card}(B_2)$ folgern.   Das zeigt,
dass zwei verschiedene Basen eines Vektor-Raums dieselbe Anzahl von Elementen haben. 
Ist diese Anzahl endlich und hat den Wert $n$, so bezeichnen wir diese Anzahl als die
\emph{\color{blue}Dimension} des Vektor-Raums $\mathcal{V}$ und definieren 
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{dim}(\mathcal{V}) := n$.


\exercise
\begin{enumerate}[(a)]
\item Zeigen Sie, dass der Vektor-Raum $\mathbb{K}^n$ die Dimension $n$ hat. 
\item Zeigen Sie, dass der Vektor-Raum $\mathbb{K}^\mathbb{N}$ keine endliche Basis hat.  \eoxs
\end{enumerate}


\section{Untervektor-Räume}
\remark
Um in den folgenden Abschnitten die Notation nicht zu schwerfällig werden zu lassen, werden wir im Falle eines
$\mathbb{K}$-Vektor-Raums $\mathcal{V} = \bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$ 
nicht mehr zwischen der Struktur $\bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$
und der Menge $V$ unterscheiden und stattdessen die Menge $V$ als $\mathbb{K}$-Vektor-Raum bezeichnen.  Sie
sollten sich darüber im Klaren sein, dass wir dann eigentlich nicht die Menge $V$ meinen, sondern
die Struktur $\bigl\langle \langle V, \vec{0}, + \rangle, \cdot \bigr\rangle$.  Falls der Körper
$\mathbb{K}$ für die Diskussion unwichtig  ist, sprechen wir auch kürzer einfach von einem Vektor-Raum.

Ähnliches gilt für einen Körper $\mathbb{K} = \langle K, 0, 1, +, \cdot \rangle$: Auch hier unterscheiden wir
in Zukunft nicht zwischen der Menge $K$ und der Struktur $\mathbb{K}$ und schreiben beispielsweise $\alpha \in
\mathbb{K}$, obwohl wir eigentlich $\alpha \in K$ meinen.
\eoxs

Ist $V$ ein Vektor-Raum und ist $U \subseteq V$, so dass $U$ für sich betrachtet ebenfalls ein
Vektor-Raum ist, so bezeichnen wir $U$ als
\blue{Untervektor-Raum} von $V$.  Eine zu dem eben Gesagten äquivalente Definition folgt.

\begin{Definition}[Untervektor-Raum]
Es sei $V$ ein $\mathbb{K}$-Vektor-Raum und es gelte $U \subseteq V$.
Dann ist $U$ ein \blue{Untervektor-Raum} von $V$ genau dann, 
wenn Folgendes gilt:
\begin{enumerate}
\item $U \not= \emptyset$,
\item $\forall \vec{x}, \vec{y} \in U: \vec{x} + \vec{y} \in U$ \quad und \quad
\item $\forall \alpha \in \mathbb{K}: \forall \vec{x} \in U: \alpha \cdot \vec{x} \in U$.  \eoxs
\end{enumerate}
\end{Definition}

Eine Teilmenge $U$ von $V$ ist also ein Untervektor-Raum von $V$, falls $U$ nicht leer ist und zusätzlich
unter Addition und Skalar-Multiplikation abgeschlossen ist.  Es lässt sich leicht zeigen, dass ein Untervektor-Raum $U$
auch selbst ein Vektor-Raum ist:  Die Gültigkeit des Assoziativ-Gesetzes und der Distributiv-Gesetze folgt einfach aus
der Tatsache, dass diese Gesetze schon in $V$ gelten und damit erst recht in $U$, denn $U$ ist ja eine Teilmenge von
$V$. 

\remark
Statt der ersten Bedingung hätten wir auch fordern können, dass $\vec{0} \in U$ gilt, denn wenn es
irgendeinen Vektor $\vec{x} \in U$ gibt,  dann ist wegen der Abgeschlossenheit von $U$ unter
Skalar-Multiplikation auch der Vektor
\\[0.2cm]
\hspace*{1.3cm}
$0 \cdot \vec{x} = \vec{0} \in U$.  
\\[0.2cm]
Umgekehrt folgt aus $\vec{0} \in U$ natürlich sofort, dass $U$ nicht leer ist.  In der Praxis werden
wir den Nachweis, dass $U \not= \emptyset$ ist, fast immer dadurch führen, dass wir $\vec{0} \in U$
zeigen. 
\eoxs

\example
Es sei $V = \mathbb{R}^3$.  Ist weiter $\vec{z} = [ z_1, z_2, z_3 ] \in \mathbb{R}^3$ und definieren wir
\\[0.2cm]
\hspace*{1.3cm}
$U := \{ \alpha \cdot \vec{z} \mid \alpha \in \mathbb{R} \}$,
\\[0.2cm]
so ist $U$ ein Untervektor-Raum des $\mathbb{R}^3$.

\proof
Es sind drei Eigenschaften zu prüfen:
\begin{enumerate}
\item Offenbar gilt $\vec{0} = 0 \cdot \vec{z} \in U$ und damit ist die erste Eigenschaft bereits gezeigt.
\item Seien $\vec{x}, \vec{y} \in U$.  Dann gibt es $\alpha, \beta \in \mathbb{R}$, so dass
      \\[0.2cm]
      \hspace*{1.3cm}
      $\vec{x} = \alpha \cdot \vec{z}$ \quad und \quad $\vec{y} = \beta \cdot \vec{z}$
      \\[0.2cm]
      gilt.  Daraus folgt unter Benutzung des Distributiv-Gesetzes
      \\[0.2cm]
      \hspace*{1.3cm}
      $\vec{x} + \vec{y} = \alpha \cdot \vec{z} + \beta \cdot \vec{z} = (\alpha + \beta) \cdot \vec{z} \in U$.
\item Sei nun $\alpha \in \mathbb{R}$ und $z \in U$.  Dann gibt es ein $\beta \in \mathbb{R}$, so dass
      $\vec{x} = \beta \cdot \vec{z}$ gilt.  Mit Hilfe des Assoziativ-Gesetzes schließen wir nun wie folgt:
      \\[0.2cm]
      \hspace*{1.3cm}
      $\alpha \cdot \vec{x} = \alpha \cdot (\beta \cdot \vec{z}) = (\alpha \cdot \beta) \cdot \vec{z} \in U$.
      \qeds
\end{enumerate}

\remark
Geometrisch handelt es sich bei der Menge $U$ um eine Gerade, die durch den Nullpunkt geht.
Das nächste Beispiel verallgemeinert das letzte Beispiel dadurch, dass nun nicht mehr ein einzelner Vektor
$\vec{z}$ den Raum $U$ erzeugt, sondern der Untervektor-Raum durch eine beliebige Menge $M$ von Vektoren
erzeugt wird.

\example
Es sei $V$ ein $\mathbb{K}$-Vektor-Raum und $M = \{\vec{x}_1,\cdots,\vec{x}_n\} \subseteq V$ sei eine nicht-leere Menge von Vektoren.  Dann definieren wir die Menge
$\textsl{span}_\mathbb{K}(M)$ als die Menge aller endlichen Linear-Kombinationen von Vektoren aus $M$, wir setzen also
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{span}_\mathbb{K}(M) := 
\bigl\{   \alpha_1 \cdot \vec{x}_1 + \cdots + \alpha_n \cdot \vec{x}_n
     \mid \alpha_i \in \mathbb{K} \;\;\mbox{f.a. $i\in\{1,\cdots,n\}$}
\bigr\}
$.
\\[0.2cm]
Dann ist die so definierte Menge $\textsl{span}_\mathbb{K}(M)$ ein Untervektor-Raum von $V$.

\proof
Es sind drei Eigenschaften zu prüfen.
\begin{enumerate}
\item Es gilt
      \\[0.2cm]
      \hspace*{1.3cm}
      $\vec{0} = 0 \cdot \vec{x}_1 + \cdots + 0 \cdot \vec{x}_n$
      \\[0.2cm]
      und daraus folgt $\vec{0} \in \textsl{span}_\mathbb{K}(M)$.
\item Es seien $\vec{x}, \vec{y} \in \textsl{span}_\mathbb{K}(M)$.  Dann gibt es $\alpha_1, \cdots, \alpha_n, \beta_1, \cdots, \beta_n \in \mathbb{K}$ 
      so dass 
      \\[0.2cm]
      \hspace*{1.3cm}
      $\vec{x} = \alpha_1 \cdot \vec{x}_1 + \cdots + \alpha_n \cdot \vec{x}_n$ \quad und \quad
      $\vec{y} = \beta_1 \cdot \vec{x}_1 + \cdots + \beta_n \cdot \vec{x}_n$ 
      \\[0.2cm]
      gilt. Damit haben wir
      \\[0.2cm]
      \hspace*{1.3cm}
      $
       \vec{x} + \vec{y} =  
          (\alpha_1 + \beta_1) \cdot \vec{x}_1 + \cdots + (\alpha_n + \beta_n) \cdot \vec{x}_n \in \textsl{span}_\mathbb{K}(M)
      $.
\item Nun sei $\vec{x} \in \textsl{span}_\mathbb{K}(M)$ und $\alpha \in \mathbb{K}$.
      Dann gibt es Skalare $\beta_1, \cdots, \beta_n$, so dass
      \\[0.2cm]
      \hspace*{1.3cm}
      $\vec{x} = \beta_1 \cdot \vec{x}_1 + \cdots + \beta_n \cdot \vec{x}_n$
      \\[0.2cm]
      gilt.  Damit haben wir
      \\[0.2cm]
      \hspace*{1.3cm}
      $\alpha \cdot \vec{x} = \alpha \cdot (\beta_1 \cdot \vec{x}_1 + \cdots + \beta_n \cdot \vec{x}_n) =
       (\alpha \cdot \beta_1) \cdot \vec{x}_1 + \cdots + (\alpha \cdot \beta_n) \cdot \vec{x}_n \in
       \textsl{span}_\mathbb{K}(M)$.
      \qeds
\end{enumerate}
\pagebreak

\example
Es sei $\mathbb{R}^{\mathbb{R}}$ die Menge der (bereits früher definierten) reellwertigen Funktionen
auf $\mathbb{R}$.
Weiter sei $c \in \mathbb{R}$ beliebig.  Definieren wir die Menge $N_c$ als
\\[0.2cm]
\hspace*{1.3cm}
$N_c := \{ f \in \mathbb{R}^{\mathbb{R}} \mid f(c) = 0 \}$,
\\[0.2cm]
also als die Menge der Funktionen $f$, die an der Stelle $c$ eine Nullstelle haben, dann ist
$N_c$ ein Untervektor-Raum von $\mathbb{R}^{\mathbb{R}}$.

\exercise
Beweisen Sie, dass $N_c$ ein Untervektor-Raum von $\mathbb{R}^{\mathbb{R}}$ ist.
\eoxs

\begin{Satz}
  Ist $V$ ein Vektor-Raum und sind $U_1$ und $U_2$ Untervektor-Räume von $V$, so ist auch die Menge
  $U_1 \cap U_2$ ein Untervektor-Raum von $V$.
\end{Satz}

\proof
Wir haben drei Eigenschaften nachzuweisen.
\begin{enumerate}
\item Da $U_1$ und $U_2$ Untervektor-Räume sind, gilt
      \\[0.2cm]
      \hspace*{1.3cm}
      $\vec{0} \in U_1$ \quad und \quad $\vec{0} \in U_2$, \quad woraus sofort \quad
      $\vec{0} \in U_1 \cap U_2$ \quad folgt.
\item Seien $\vec{x}, \vec{y} \in U_1 \cap U_2$.  Dann gilt natürlich
      \\[0.2cm]
      \hspace*{1.3cm}
      $\vec{x} \in U_1$, \quad 
      $\vec{x} \in U_2$, \quad 
      $\vec{y} \in U_1$, \quad und \quad
      $\vec{y} \in U_2$.
      \\[0.2cm] 
      Da $U_1$ und $U_2$ Untervektor-Räume sind, folgt dann
      \\[0.2cm]
      \hspace*{1.3cm}
      $\vec{x} + \vec{y} \in U_1$ \quad und \quad $\vec{x} + \vec{y} \in U_2$,
      \\[0.2cm]
      also insgesamt
      \\[0.2cm]
      \hspace*{1.3cm}
      $\vec{x} + \vec{y} \in U_1 \cap U_2$.
\item Sei nun $\vec{x} \in U_1 \cap U_2$ und $\alpha \in \mathbb{K}$.  Daraus folgt sofort
      \\[0.2cm]
      \hspace*{1.3cm}
      $\vec{x} \in U_1$ \quad und \quad
      $\vec{x} \in U_2$.
      \\[0.2cm] 
      Da $U_1$ und $U_2$ Untervektor-Räume sind, können wir folgern, dass
      \\[0.2cm]
      \hspace*{1.3cm}
      $\alpha \cdot \vec{x} \in U_1$ \quad und \quad $\alpha \cdot \vec{x} \in U_2$
      \\[0.2cm]
      gilt, so dass wir insgesamt
      \\[0.2cm]
      \hspace*{1.3cm}
      $\alpha \cdot \vec{x} \in U_1 \cap U_2$
      \\[0.2cm]
      haben.  \qeds
\end{enumerate}

\exercise
Es sei $V$ ein Vektor-Raum und $U_1$ und $U_2$ seien Untervektor-Räume von $V$.  Beweisen oder widerlegen Sie, dass
dann auch die Menge $U_1 \cup U_2$ ein Untervektor-Raum von $V$ ist.
\eoxs


\section{Euklidische Vektor-Räume}
Wollen wir in einem Vektor-Raum Geometrie betreiben, so benötigen wir eine zusätzliche Struktur,
die es uns ermöglicht,  Begriffe wie die Länge eines Vektors oder den Winkel zwischen
zwei Vektoren zu definieren.  Eine solche zusätzliche Struktur ist beispielsweise in
\href{https://de.wikipedia.org/wiki/Euklidischer_Raum}{euklidischen Vektor-Räumen} gegeben.  Wir
führen diesen Begriff jetzt ein.

\begin{Definition}[Skalar-Produkt, Euklidischer Vektor-Raum] \lb
  Es sei $V$ ein $\mathbb{R}$-Vektor-Raum.  Eine Abbildung 
  \\[0.2cm]
  \hspace*{1.3cm}
  $\langle \cdot \mid \cdot \rangle: V \times V \rightarrow \mathbb{R}$
  \\[0.2cm]
  ist ein \blue{Skalar-Produkt} genau dann, wenn die folgenden Bedingungen erfüllt sind:
  \begin{enumerate}
  \item Die Abbildung $\langle \cdot\mid \cdot \rangle$ ist \blue{bilinear}, das heißt es gelten die
        folgenden Gleichungen:
        \begin{enumerate}
        \item $\langle \vec{x} + \vec{y}\mid \vec{z} \rangle = \langle \vec{x}\mid \vec{z} \rangle + \langle \vec{y}\mid \vec{z} \rangle$
              \quad für alle $\vec{x}, \vec{y}, \vec{z} \in V$.
        \item $\langle \alpha \cdot \vec{x}\mid \vec{y} \rangle = \alpha \cdot \langle \vec{x}\mid \vec{y} \rangle$
              \quad für alle $\vec{x}, \vec{y} \in V$ und alle $\alpha \in \mathbb{R}$.
        \end{enumerate}
  \item Die Abbildung  $\langle \cdot\mid \cdot \rangle$ ist \blue{symmetrisch}, das heißt es gilt
        \\[0.2cm]
        \hspace*{1.3cm}
        $\langle \vec{x}\mid \vec{y} \rangle = \langle \vec{y}\mid \vec{x} \rangle$ 
        \quad für alle $\vec{x}, \vec{y} \in V$.
  \item Die Abbildung   $\langle \cdot\mid \cdot \rangle$ ist \blue{positiv definit}, das heißt es
        gilt:
        \begin{enumerate}
        \item $\langle \vec{x}\mid \vec{x} \rangle \geq 0$ \quad für alle $\vec{x} \in V$,
        \item $\langle \vec{x}\mid \vec{x} \rangle = 0 \;\Leftrightarrow\; \vec{x} = \vec{0}$ \quad für alle $\vec{x} \in V$.
        \end{enumerate}
  \end{enumerate} 
  Falls auf einem Vektor-Raum $V$ ein Skalar-Produkt $\langle \cdot \mid \cdot \rangle$ definiert
  ist, so nennen wir $V$ einen \blue{euklidischen Vektor-Raum}.  \eoxs
\end{Definition}

\remark
Aus der Symmetrie und der Gleichung $\langle \vec{x} + \vec{y}\mid \vec{z} \rangle = \langle \vec{x}\mid\vec{z} \rangle + \langle \vec{y}\mid \vec{z} \rangle$
folgt sofort, dass auch
\\[0.2cm]
\hspace*{1.3cm}
$\langle \vec{x}\mid \vec{y} + \vec{z} \rangle = \langle \vec{x}\mid \vec{y} \rangle + \langle \vec{x}\mid \vec{z} \rangle$
für alle $\vec{x}, \vec{y}, \vec{z} \in V$ gilt.
\\[0.2cm]
Ähnlich folgt aus der Symmetrie und der Gleichung  $\langle \alpha \cdot \vec{x}\mid \vec{y} \rangle = \alpha \cdot \langle \vec{x}\mid \vec{y} \rangle$,
dass auch
\\[0.2cm]
\hspace*{1.3cm}
$\langle \vec{x}\mid \alpha \cdot \vec{y} \rangle = \alpha \cdot \langle \vec{x}\mid \vec{y} \rangle$
\quad für alle $\vec{x}, \vec{y} \in V$ und alle $\alpha \in \mathbb{R}$ gilt.
\\[0.2cm]
Damit sehen wir, dass ein Skalar-Produkt in beiden Argumenten linear ist.  Wir sagen daher, dass das
Skalar-Produkt \blue{bilinear} ist.
\eox

\example
Definieren wir auf der Menge $\mathbb{R}^n$ ein Produkt $\langle \cdot \mid \cdot \rangle$ durch die Festlegung 
\\[0.2cm]
\hspace*{1.3cm}
$\ds\bigl\langle [x_1, \cdots, x_n] \bigm| [y_1, \cdots, y_n] \bigr\rangle := \sum\limits_{i=1}^n x_i \cdot y_i$,
\\[0.2cm]
so ist die so definierte Abbildung $\langle \cdot \mid \cdot \rangle$ ein Skalar-Produkt und mit
diesem Produkt ist $\mathbb{R}^n$ dann ein euklidischer Vektor-Raum.  \eoxs

\exercise
Beweisen Sie, dass der $\mathbb{R}^n$ zusammen mit der oben gegebenen Definition des Skalar-Produkts
ein euklidischer Vektor-Raum ist.  \eox


Falls $V$ ein euklidischer Vektor-Raum ist, so lässt sich für die Vektoren $\vec{x} \in V$ eine \blue{Norm}
einführen, die durch
\\[0.2cm]
\hspace*{1.3cm}
$\|\vec{x}\| := \sqrt{\langle \vec{x} \mid \vec{x} \rangle}$
\\[0.2cm]
definiert wird.  Diese Norm kann als die Länge des Vektors $\vec{x}$ interpretiert werden, denn sie
stimmt im Falle des $\mathbb{R}^2$ und des $\mathbb{R}^3$ mit der Länge des Vektors $\vec{x}$
überein.  Zwischen der Norm und dem Skalar-Produkt gibt es eine wichtige Beziehung, die wir als die
Cauchy-Schwarzsche Ungleichung
(\href{https://de.wikipedia.org/wiki/Augustin-Louis_Cauchy}{Augustin-Louis Cauchy}, 1789 - 1857,
\href{https://de.wikipedia.org/wiki/Hermann_Amandus_Schwarz}{Hermann Amandus Schwarz}, 1843 - 1921) 
bezeichnen.

\begin{Satz}[Cauchy-Schwarzsche Ungleichung] \lb
  Es sei $V$ ein euklidischer Vektor-Raum mit dem Skalar-Produkt $\langle \cdot \mid \cdot \rangle$.
  Dann gilt
  \\[0.2cm]
  \hspace*{1.3cm}
  $\bigl|\langle \vec{x}, \vec{y} \rangle\bigr| \leq \| \vec{x} \| \cdot \|\vec{y}\|$ 
  \quad für alle $\vec{x}, \vec{y} \in V$.
\end{Satz}

\proof
Für beliebiges $\alpha \in \mathbb{R}$ gilt
\\[0.2cm]
\hspace*{1.3cm}
$\langle \vec{x} - \alpha \cdot \vec{y} \mid \vec{x} - \alpha \cdot \vec{y} \rangle \geq 0$,
\\[0.2cm]
denn die Abbildung $\langle \cdot \mid \cdot \rangle$ ist positiv definit.
Nutzen wir nun die Bilinearität der Abbildung $\langle \cdot \mid \cdot \rangle$, so können wir
diese Ungleichung auch als
\\[0.2cm]
\hspace*{1.3cm}
$\langle \vec{x} \mid \vec{x} \rangle - \alpha \cdot \langle \vec{x}\mid \vec{y} \rangle  - 
\alpha \cdot \langle \vec{y} \mid \vec{x} \rangle + \alpha^2 \cdot \langle \vec{y} \mid \vec{y} \rangle \geq 0$
\\[0.2cm]
schreiben.  Nutzen wir nun die Symmetrie der Abbildung $\langle \cdot \mid \cdot \rangle$ aus,
so vereinfacht sich diese Ungleichung zu der Ungleichung
\\[0.2cm]
\hspace*{1.3cm}
$\langle \vec{x} \mid \vec{x} \rangle - 2 \cdot \alpha \cdot \langle \vec{x}\mid \vec{y} \rangle  
 + \alpha^2 \cdot \langle \vec{y} \mid \vec{y} \rangle \geq 0
$.
\\[0.2cm]
Diese Ungleichung gilt für alle $\alpha \in \mathbb{R}$ und damit auch, wenn wir
\\[0.2cm]
\hspace*{1.3cm}
$\ds\alpha := \frac{\langle \vec{x} \mid \vec{y} \rangle}{\langle \vec{y} \mid \vec{y} \rangle}$
\\[0.2cm]
definieren.  Setzen wir diesen Wert oben ein, so erhalten wir die Ungleichung
\\[0.2cm]
\hspace*{1.3cm}
$\ds\langle \vec{x} \mid \vec{x} \rangle - 
 2 \cdot \frac{\langle \vec{x} \mid \vec{y} \rangle}{\langle \vec{y} \mid \vec{y} \rangle} \cdot \langle \vec{x}\mid \vec{y} \rangle  
 +  \left(\frac{\langle \vec{x} \mid \vec{y} \rangle}{\langle \vec{y} \mid \vec{y} \rangle}\right)^2 \cdot \langle \vec{y} \mid \vec{y} \rangle \geq 0
$.
\\[0.2cm]
Multiplizieren wir diese Ungleichung mit $\langle \vec{y} \mid \vec{y} \rangle$, so erhalten wir die
Ungleichung 
\\[0.2cm]
\hspace*{1.3cm}
$\ds\langle \vec{x} \mid \vec{x} \rangle \cdot \langle \vec{y} \mid \vec{y} \rangle - 
 2 \cdot \langle \vec{x} \mid \vec{y} \rangle \cdot \langle \vec{x} \mid \vec{y} \rangle  
 +  \bigl(\langle \vec{x} \mid \vec{y} \rangle\bigr)^2  \geq 0
$,
\\[0.2cm]
die wir zu 
\\[0.2cm]
\hspace*{1.3cm}
$\ds\langle \vec{x} \mid \vec{x} \rangle \cdot \langle \vec{y} \mid \vec{y} \rangle \geq \bigl(\langle \vec{x} \mid \vec{y} \rangle\bigr)^2$
\\[0.2cm]
vereinfachen können.  Ziehen wir hier auf beiden Seiten die Wurzel und berücksichtigen die
Definition der Norm $\|\vec{x}\|$, so erhalten wir
\\[0.2cm]
\hspace*{1.3cm}
$\|\vec{x}\| \cdot \|\vec{y}\| \geq \bigl|\langle \vec{x} \mid \vec{y} \rangle\bigr|$
\\[0.2cm]
und das ist die Cauchy-Schwarzsche Ungleichung.  \qed

\remark
Die Cauchy-Schwarzsche Ungleichung ermöglicht es, den Winkel $\varphi$ zwischen zwei Vektoren $\vec{x}$ und $\vec{y}$
eines euklidischen Vektor-Raums zu definieren, denn wir können vereinbaren, dass
\\[0.2cm]
\hspace*{1.3cm}
  \colorbox{blue}{\framebox{\colorbox{yellow}{
$\ds\cos(\varphi) := \frac{\langle \vec{x} \mid \vec{y} \rangle}{\|\vec{x}\| \cdot \|\vec{y}\|}$
}}}
\\[0.2cm]
gilt.  Aus der Cauchy-Schwarzschen Ungleichung folgt dann, dass für den so definierten Wert
$\cos(\varphi)$ die Ungleichung
\\[0.2cm]
\hspace*{1.3cm}
$-1 \leq \cos(\varphi) \leq 1$
\\[0.2cm]
gilt und damit sichergestellt ist, dass diese Größe tatsächlich als Kosinus eines Winkels interpretiert werden
kann.  
\eoxs

\exercise
Beweisen Sie, dass im $\mathbb{R}^2$ der Winkel, der zwischen zwei Vektoren $\vec{a}$ und $\vec{b}$
eingeschlossen wird,  der Gleichung
\\[0.2cm]
\hspace*{1.3cm}
$\ds\cos(\varphi) := \frac{\langle \vec{a} \mid \vec{b} \rangle}{\|\vec{a}\| \cdot \|\vec{b}\|}$
\\[0.2cm]
genügt.  Zur Vereinfachung können Sie sich auf den Fall beschränken, dass die 
beiden Vektoren $\vec{a}$ und $\vec{b}$ im ersten Quadranten liegen.
\eoxs

\begin{Satz}[Dreiecks-Ungleichung] 
   Es sei $V$ ein euklidischer Vektor-Raum.  Dann gilt
   \\[0.2cm]
   \hspace*{1.3cm}
   $\|\vec{x}+\vec{y}\| \leq \|\vec{x}\| + \|\vec{y}\|$ \quad für alle $\vec{x}, \vec{y} \in V$.  
   \\[0.2cm]
   Diese Ungleichung wird als
   \href{https://de.wikipedia.org/wiki/Dreiecksungleichung}{Dreiecks-Ungleichung} bezeichnet, denn
   Sie besagt,  dass in einem Dreieck, bei dem zwei der Seiten durch die Vektoren $\vec{x}$ und $\vec{y}$ gegeben
   sind, die Länge der dritten Seite, die durch den Vektor $\vec{x} + \vec{y}$ dargestellt wird, 
   kleiner als die Summe der Längen der beiden anderen Seiten ist.
\end{Satz}

\proof
Wir haben die die folgende Kette von Gleichungen und Ungleichungen:
\\[0.2cm]
\hspace*{1.3cm}
$
\begin{array}[t]{lcll}
  \|\vec{x} + \vec{y}\|^2 & = & \langle \vec{x} + \vec{y} \mid  \vec{x} + \vec{y} \rangle \\[0.2cm]
                          & = & \langle \vec{x} \mid \vec{x} \rangle + 
                                2 \cdot \langle \vec{x} \mid \vec{y} \rangle + 
                                \langle \vec{y} \mid \vec{y} \rangle \\[0.2cm]
                          & = & \|\vec{x}\|^2 + 2 \cdot \langle \vec{x} \mid \vec{y} \rangle + \|\vec{y}\|^2 \\[0.2cm]
                          & \leq & \|\vec{x}\|^2 + 2 \cdot |\langle \vec{x} \mid \vec{y} \rangle| + \|\vec{y}\|^2 \\[0.2cm]
                          & \leq & \|\vec{x}\|^2 + 2 \cdot \|\vec{x}\| \cdot \|\vec{y}\| + \|\vec{y}\|^2 \\[0.2cm]
                          & = & \bigl(\|\vec{x}\| + \|\vec{y}\|\bigr)^2 
\end{array}
$
\\[0.2cm]
Im vorletzten Schritt haben wir die Cauchy-Schwarzsche Ungleichung benutzt.  Insgesamt haben wir
gezeigt, dass
\\[0.2cm]
\hspace*{1.3cm}
$\|\vec{x} + \vec{y}\|^2 \leq \bigl(\|\vec{x}\| + \|\vec{y}\|\bigr)^2$
\\[0.2cm] 
gilt.  Ziehen wir auf beiden Seiten dieser Ungleichung die Wurzel, so erhalten wir die Behauptung.  
\qed

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "lineare-algebra"
%%% ispell-local-dictionary: "deutsch8"
%%% End: 
